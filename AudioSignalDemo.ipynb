{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 音響信号の基礎的なデモ\n",
    "\n",
    "このデモは音の信号を全く扱ったことのない人向けのデモンストレーションです。\n",
    "\n",
    "音のデジタル信号について会話するときに、最低限知っておいて欲しいことを書いています。\n",
    "\n",
    "高校の物理で波について学習したことがあることを前提として記述しています。ご了承ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wave\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 音響信号についての最低限の知識\n",
    "\n",
    "音は空気の振動によって伝わります。\n",
    "\n",
    "それをコンピュータ上で扱うためには、アナログ→デジタルの変換(AD変換)が必要です。\n",
    "\n",
    "AD変換の際は、アナログの波形を**時間方向**と**振幅方向**の2方向についてデジタル化する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 標本化\n",
    "時間方向へのデジタル化を、**標本化**もしくは**サンプリング**と言います。\n",
    "\n",
    "1秒間に取るサンプル数が多いほど、そのデジタル信号は高い音まで再現することができます。\n",
    "\n",
    "**サンプリング周波数**(fs [Hz])は、その1秒間に取るサンプル数を指します。\n",
    "\n",
    "CD音源だとfs = 44100[Hz]、プロ用の音源だとfs=48000[Hz]が一般的です。\n",
    "\n",
    "最近話題のハイレゾ音源はfs=96000[Hz]と、非常に高いサンプリング周波数を有しています。\n",
    "\n",
    "ちなみに、デジタル音源はサンプリング周波数の1/2の周波数まで再現できます([サンプリング定理](http://www.ic.is.tohoku.ac.jp/~swk/lecture/yaruodsp/sampling.html))。\n",
    "\n",
    "なので、fs = 48000[Hz]の場合、理論的には24000[Hz]まで再現できることになります。\n",
    "\n",
    "人間の聴覚は大体20~20000[Hz]の帯域を音として認識できるとされているので、\n",
    "\n",
    "これくらいで十分ということになります。\n",
    "\n",
    "逆に、音声データを扱うときに、8000[Hz]程度までしか用いないのであれば、\n",
    "\n",
    "サンプリング周波数を20000[Hz]程度まで下げても問題はないし、そのほうがデータ量を削減できます。\n",
    "\n",
    "これをダウンサンプリングと言います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 量子化\n",
    "振幅方向のデジタル化を、**量子化**と言います。\n",
    "\n",
    "振幅方向の分割が多いほど、より精密に音を再現できます。\n",
    "\n",
    "一般的に16bitが用いられることが多いです。\n",
    "\n",
    "これは、人間の聴覚のダイナミックレンジが100[dB]程度であることに起因します。\n",
    "\n",
    "ハイレゾ音源だと、24bitが用いられています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 周波数特性\n",
    "\n",
    "フーリエ解析を大学の授業でさらったことがある人ならなんとなくお分かりかと思いますが、\n",
    "\n",
    "音のデータは**時間特性**および**周波数特性**の2つの特性を持っています。\n",
    "\n",
    "時間特性というのは、普段みなさんがみたことあるような、下のような波形を表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上で述べた標本化や量子化も時間特性について述べた話です。\n",
    "\n",
    "時間特性から周波数特性へと変換する際に、離散フーリエ変換を用います。\n",
    "\n",
    "正確には高速フーリエ変換なのですが、難しい話になるので、\n",
    "\n",
    "勉強したい方は[こちら](http://www.ic.is.tohoku.ac.jp/~swk/lecture/yaruodsp/dft.html)をご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wavファイル\n",
    "\n",
    "以上のようにして、アナログの音圧信号はデジタル信号へと変換されます。\n",
    "\n",
    "通常は、.wavという拡張子を持つwavファイルとして保存されます。\n",
    "\n",
    "これは非圧縮の音声データで、バイナリで記録されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
